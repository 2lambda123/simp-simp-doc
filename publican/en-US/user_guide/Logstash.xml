<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE chapter [
<!ENTITY % BOOK_ENTITIES SYSTEM "../SIMP_Documentation.ent">
%BOOK_ENTITIES;
]>
<chapter id="ch-ug-Logstash">
  <chapterinfo>
    <title id="ch-ug-Logstash-title">Logstash</title>
    <affiliation>
      <orgname>SIMP Team</orgname>
    </affiliation>
    <keywordset>
      <keyword>Logstash</keyword>
    </keywordset>
    <itermset>
      <indexterm>
        <primary>Logstash</primary>
        <secondary>Audit</secondary>
        <seealso>Audit</seealso>
      </indexterm>
      <indexterm>
        <primary>Logstash</primary>
        <seealso>Audit</seealso>
      </indexterm>
    </itermset>
  </chapterinfo>
  <title>Logstash</title>
  <para>
    This chapter gives instruction for getting a basic configuration of
    Logstash working in a SIMP environment.
   </para>
   <section id="sect-ug-logstash-background">
      <title id="sect-ug-logstash-title">Logstash</title>
      <para>
        <ulink url="http://logstash.net/">Logstash</ulink> is an open source
        tool that provides a means for SIMP implementations to have logs and
        events collected, searched, and forwarded (filtered or unfiltered) to
        another host.  SIMP comes with three separate but related modules.  The
        modules are:
      </para>
      <para>
        <itemizedlist mark="bullet">
          <listitem>
            <para>
              <emphasis role="bold">Logstash:</emphasis>Installs the RPMs and
              configuration needed for log inputs, filters, and outputs.
              </para>
          </listitem>
          <listitem>
            <para>
              <emphasis role="bold">Kibana:</emphasis>Installs the RPMs and
              configuration needed for the Kibana 3 web interface.
            </para>
          </listitem>
          <listitem>
            <para>
              <emphasis role="bold">Elasticsearch:</emphasis>Installs the RPMs
              and configuration needed for Elasticsearch.
            </para>
          </listitem>
        </itemizedlist>
      </para>
      <warning>
        <para>
          The Logstash class is incompatible with the SIMP
          rsyslog::stock::server class!  You cannot enable both of them on
          the same sever.
        </para>
      </warning>
        <section id="sect-ug-logstash-architecture">
          <title id="sect-ug-logstash-architecture-title">Logstash Architecture</title>
          <para>
            The overall model for Logstash is very simple.  It takes inputs
            from various sources, optionally applies filters, and outputs
            the results to a specified target.  It's likely that you can already
            forward logs to Logstash and output them in a useful format as part
            of your existing architecture.
          </para>
          <para>
            Logstash filters can manipulate logs after ingest and before
            output.  Examples of existing filters include fixing logs to
            split/combine lines, adding fields, normalizing time stamps, and
            adding GeoIP fields.  Depending on the type of log manipulation
            that is desired, there is likely a filter and <ulink url="http://logstash.net/docs/1.1.10/">
            associated documentation</ulink> that already exists.
          </para>
        </section>
        <section id="sect-ug-logstash-simp-architecture">
          <title id="sect-ug-logstash-simp-architecture-title">Logstash SIMP Architecture</title>
          <para>
            Applying the SIMP Logstash, Elasticsearch, and Kibana
            modules provides an implementation with a functioning log
            reduction and search capability. Unless scale dictates
            otherwise, these three modules can easily be applied to a
            single host.
          </para>
          <para>
            The intent of providing Logstash in SIMP is to replace the default
            Rsyslog server with a capability that is easier to search and
            analyze over time. Once your Logstash server is set up, you simply
            need to direct your hosts to forward logs to your Logstash
            server. In a default SIMP configuration, this can be done by
            setting the $log_server variable in hiera.
            <note>
              <para>
                SIMP does <emphasis role="bold">NOT</emphasis> apply any filters to the
                logs by default.
              </para>
            </note>
            It is up to each implementation to define and apply filters that
            meet their local requirements. While multiple output targets may be
            defined, SIMP only defines the Elasticsearch output by default.
            Please see the Elasticsearch Puppet module for details on how to
            define additional output targets.
          </para>
          <mediaobject>
            <imageobject>
              <imagedata fileref="images/Logstash.svg" align="center" scale="100"/>
             </imageobject>
            <textobject>
              <phrase>SIMP Logstash Flow</phrase>
            </textobject>
            <caption>
              SIMP Logstash Flow
            </caption>
          </mediaobject>
        </section>
        <section id="sect-ug-logstash-simp-security">
          <title id="sect-ug-logstash-simp-security-title">Logstash, SIMP, and Security</title>
          <para>
            The provided SIMP modules for Logstash, Elasticsearch, and Kibana
            have been built with connection security in mind. Overriding these settings
            could adversely effect the security of the logging infrastructure.
            The following list describes the security features in place with
            the default SIMP module settings:
          </para>
          <warning>
            <para>
              The native (Java) Elasticsearch connections are not
              encrypted!  This will be remedied in the future as
              sufficient methods are found.
            </para>
          </warning>
          <para>
            <itemizedlist mark="bullet">
              <listitem>
                <para>
                  <emphasis role="bold">User Name and Password Protection for
                  Kibana:</emphasis>The Kibana web can be exposed to a defined
                  list of hosts.  If you are connecting to Kibana from anything
                  other than the localhost, a user name and password is
                  required for authentication. Both LDAP and local database
                  users are supported.
                </para>
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Syslog over Stunnel:</emphasis>The
                  default behavior in SIMP is to encrypt syslog traffic over
                  Stunnel.  This remains the case with Logstash. Unencrypted
                  traffic is also supported for network devices.
                </para>
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Limiting Web Actions:</emphasis>The
                  Kibana module restricts what HTTP commands a user can
                  perform on the Elasticsearch data store. Full POST action
                  must be given to the Logstash nodes and some nodes may
                  require DELETE capabilities. Logstash hosts should be tightly
                  controlled so that administrative users cannot modify data
                  inside of Elasticsearch with carefully crafted commands. This
                  is one reason that we use syslog on the local hosts.
                </para>
              </listitem>
            </itemizedlist>
          </para>
          <important>
            <para>
              The Puppet modules for Logstash, Kibana, and Elasticsearch
              contain dozens of variables that may be manipulated.  You should
              read each product's documentation and ensure you understand any
              setting that is changed from the default SIMP values.  Changes
              can effect both security and functionality of the system.
            </para>
          </important>
        </section>
    </section>
    <section id="sect-ug-logstash-setup">
      <title>Logstash Setup</title>
      <section id="sect-ug-logstash-system-requirements">
        <title>Logstash System Requirements</title>
        <para>
          The storage requirements for Logstash and Elasticsearch vary
          depending on how long you plan on keeping logs.  If you use the
          settings in <xref linkend="sect-ug-logstash-example"/>, then your
          logs are not being filtered and are being sent to Elasticsearch.
          When using Elasticsearch, the logs are formatted for Elasticsearch
          and stored in /srv/elasticsearch.  You can also configure how many
          days of data you wish to keep in Elasticsearch (keep_days => '99').
          Therefore, you should ensure you have enough space on /srv to keep
          your defined number of days worth of logs.
        </para>
        <para>
          As you grow your Elasticsearch cluster to handle increasing log
          loads, you will want to ensure that your keep_days is set to handle
          your entire cluster appropriately.
        </para>
        <note>
          <para>
            You should have at least 4G of memory available on any Elasticsearch
            node.
          </para>
        </note>
        <important>
          <para>
            You should NOT install Logstash, Elasticsearch, nor Kibana on
            your Puppet master.  There will likely be conflicts with Apache and
            resource limitations.
          </para>
        </important>
      </section>
      <section id="sect-ug-logstash-example">
        <title>Logstash Module Recommended SIMP Setup</title>
        <para>
          The following example manifest can be applied to a single host with a
          large /srv volume and 4GB of memory.
        </para>
        <example>
          <title>Recommended Logstash Setup</title>
          <programlisting language="Ruby">
      ---
      # Add these settings to only your Logstash node.

      apache::ssl::sslverifyclient: %{hiera('kibana::ssl_verify_client')}

      kibana::redirect_web_root: true
      kibana::ssl_allowroot: %{hiera('client_nets')}
      kibana::ssl_verify_client: 'none'
      # You can add more groups under ldap_groups if you want others
      # to be able to access your Kibana instance.
      #
      # Remember, whitespace matters!
      #
      kibana::method_acl:
        'method':
          'ldap':
            'enable': true
        'limits':
          'users':
            'valid-user': 'defaults'
          'ldap_groups':
            'cn=administrators,ou=Group,dc=your,dc=domain': 'defaults'

      logstash::simp::keep_days: '30'

      elasticsearch::simp::manage_httpd: 'conf'

      classes:
        - 'logstash::simp'
        - 'kibana'
          </programlisting>
        </example>

        <para>
          In the case of the Elasticsearch node setup below, it may be
          better to use a group match to pull your Hiera settings.

          To do this, you should add the following to a file like
          /etc/puppet/manifests/nodegroups.pp
        </para>

        <programlisting language="Ruby">
      if $trusted['certname'] =~ /es\d+\.your\.domain/ {
        $hostgroup = 'elasticsearch'
      }
        </programlisting>

        <para>
          Then, ensure that a file called 'elasticsearch.yaml' is
          present in the /etc/puppet/hieradata/hostgroups directory
          and contains the following content.
        </para>
        <example>
          <title>Recommended Elasticsearch Node Setup</title>
          <programlisting language="Ruby">
      ---
      # All nodes running elasticsearch in your cluster should use
      # these settings.
      elasticsearch::simp::cluster_name: 'a_unique_hard_to_guess_name'
      # This can be no more than the total number of ES nodes that you
      # have in your cluster.
      elasticsearch::simp::replicas: '2'
      elasticsearch::simp::java_install: true

      classes:
        - 'elasticsearch::simp'
          </programlisting>
        </example>
        <para>
          Make sure you point your clients to the Logstash server by setting
          the 'log_server' variable to the fqdn of the Logstash server in
          hiera. This is further covered in <xref linkend="sect-ug-Centralized_Logging-Clients"/>.
        </para>
        <section id="sect-ug-logstash-usage">
          <title>Using LogStash and ElasticSearch</title>
          <para>
            With the default settings applied, you should be able to connect to
            port 443 on your Kibana host.  If connecting from localhost, you will not be prompted
            for a password. If you are connecting from an external host, a
            valid LDAP account with that user being defined in the Kibana Class
            is needed.  The page is SSL protected so use
            https://&lt;hostname&gt;/kibana
          </para>
          <para>
            With the web interface up, you now have the ability to search logs.
          </para>
          <para>
            There are several resources available to help with searching. The
            Kibana <ulink url="http://www.elasticsearch.org/overview/kibana/">
            Overview Page</ulink> and <ulink url="http://www.elasticsearch.org/guide/">
            Elasticsearch Guide</ulink> are a good place to start. You should also visit the
            main <ulink url="http://logstash.net/"> Logstash page</ulink> to
            see demonstrations and read their tips for searching logs.
          </para>
        </section>
      </section>
    </section>
</chapter>
